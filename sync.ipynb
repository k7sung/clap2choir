{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sync.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1VfVaaP1v4uYjGIhKj0QOPPs6bqTFsnlT",
      "authorship_tag": "ABX9TyNcbGbgF/tGzzTiGJUh++Ci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k7sung/clap2choir/blob/master/sync.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiiPrWqxhWj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SONG_NAME = \"A Promise\" #@param [\"A Promise\", \"On Eagle's Wings\"]\n",
        "\n",
        "SHARED_FOLDER_PATH = 'Shared drives/CR ESSC Virtual Choir' #@param {type:\"string\"}\n",
        "VID_FILE_GLOBS = [\"*.mov\",\"*.MOV\", \"*.mp4\"]\n",
        "AUD_FILE_GLOBS = [\"*.m4a\", \"*.mp3\", \"*.acc\", \"*.wav\"]\n",
        "\n",
        "VIDEO_RES = \"1920x1080\" #@param [\"1920x1080\", \"960x540\", \"540x360\"] \n",
        "# SYNC_MODE = \"Auto\" #@param[\"Auto\", \"Clap\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyMFlhnOV83q",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "## OPTIONAL PARAMS ##\n",
        "TIME_ZONE = 'US/Central' #@param [\"US/Central\", \"Europe/London\", \"Asia/Taipei\"] {allow-input:true}\n",
        "OUTPUT_SOLO = True #@param {type:\"boolean\"}\n",
        "OUTPUT_COMPARE = True #@param {type:\"boolean\"}\n",
        "VID_DOWNSCALE_RATIO =  6#@param {type:\"integer\"}\n",
        "INCLUDE_CLAPS = False #@param {type:\"boolean\"}\n",
        "#PREPEND_METRONOME = False #@param {type:\"boolean\"}\n",
        "\n",
        "OUTPUT_TILED_VID = True #@param {type:\"boolean\"}\n",
        "SUBTITLE_FILENAME = \"\" #@param {type:\"string\"}\n",
        "RENDER_SUBTITLE = SUBTITLE_FILENAME != \"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb1Ed5ZpOGyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytz\n",
        "from datetime import datetime, timezone\n",
        "tz = pytz.timezone(TIME_ZONE)\n",
        "now = datetime.now(tz)\n",
        "TODAY_DATE = now.strftime(\"%m%d\")\n",
        "\n",
        "SHARED_FOLDER_PATH = \"/content/drive/\" + SHARED_FOLDER_PATH\n",
        "RAW_PATH = SHARED_FOLDER_PATH + f\"/inputs/{SONG_NAME}/\"\n",
        "INPUT_PATH = SHARED_FOLDER_PATH + f\"/scaled/{SONG_NAME}/\"\n",
        "# INPUT_PATH = f\"/content/scaled/{SONG_NAME}/\"\n",
        "OUTPUT_PATH = SHARED_FOLDER_PATH + f\"/outputs/{TODAY_DATE}/{SONG_NAME}/\"\n",
        "# OUTPUT_PATH = f\"/content/outputs/{TODAY_DATE}/{SONG_NAME}/\"\n",
        "W,H = [int(t) for t in VIDEO_RES.split(\"x\")]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8dYiue_OAem",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### would be nice:\n",
        "* If output_video option is not included, don't generate scaled video\n",
        "* prepend metronome option\n",
        "* auto sync option\n",
        "* Loudness normalization (currently peak normalization). But supported in ffmpeg!\n",
        "* Easier mounting mechanism of Google Drive?\n",
        "* Better clap detection that also uses amplitude and time since last peak\n",
        "* Noise removal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gM-LbC3JkIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "### need to add the shared folder to my drive (\"Add to my drive\") in Google Drive first\n",
        "# drive.mount(\"/content/drive\")\n",
        "#%cd \"$SHARED_FOLDER_PATH\"\n",
        "%mkdir -p \"$INPUT_PATH\"\n",
        "%mkdir -p \"$OUTPUT_PATH\"\n",
        "%mkdir -p \"$OUTPUT_PATH\"/compare\n",
        "%mkdir -p \"$OUTPUT_PATH\"/solo\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwYT4mWJ73RA",
        "colab_type": "text"
      },
      "source": [
        "### Find videos to resize and trim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayxmkQhKBRp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import getmtime\n",
        "from pathlib import Path\n",
        "\n",
        "raw_paths = list(Path(RAW_PATH).iterdir()) #, key=os.path.getmtime\n",
        "cached_paths = list(Path(INPUT_PATH).iterdir())\n",
        "cached_files = dict([(c.name, getmtime(c)) for c in cached_paths])\n",
        "\n",
        "to_process = []\n",
        "#create or update\n",
        "for i in raw_paths:\n",
        "  if i.name.startswith('_') or i.name.endswith(\".sub\"):\n",
        "    continue\n",
        "  if i.name in cached_files:\n",
        "    if getmtime(i) > cached_files[i.name]:\n",
        "      to_process.append(i.name) #update\n",
        "  else:\n",
        "    to_process.append(i.name) #create\n",
        "#delete\n",
        "to_delete = cached_files.keys() - set([i.name for i in raw_paths])\n",
        "\n",
        "print(to_process)\n",
        "print(to_delete)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DR-DQJaJxqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name in to_delete:\n",
        "  print(\"removing \", name)\n",
        "  os.remove(INPUT_PATH+name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XksDT9OzJ9Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import mean, median, std, var, diff, correlate as corr, zeros, transpose\n",
        "from moviepy.editor import *\n",
        "from moviepy.audio.AudioClip import AudioArrayClip\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from os.path import basename\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations as comb\n",
        "from random import shuffle, randint\n",
        "import shutil\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yIQ_SYAQ-67",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### function to find the clapping sounds ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Zpk_ItKHb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_regular_patterns(ts):\n",
        "    candi_vars = [[var(diff([ts[i] for i in c])), c] for c in comb(range(len(ts)), 4)]\n",
        "    most_regular = min(candi_vars)\n",
        "    return [ts[t] for t in most_regular[1]]\n",
        "\n",
        "def get_tops(peak_ts, peak_vals, d_peak_vals, top_n):\n",
        "    tops = sorted([(t, 0.0*v+1.0*dv) for t, v, dv in zip(peak_ts, peak_vals, d_peak_vals)], key=lambda k:k[1], reverse=True)[:top_n]\n",
        "    #print(\"tops: \", tops)\n",
        "    return tops\n",
        "\n",
        "def estimate_start(audio, search_secs=20, is_finetune=False):\n",
        "    c_dur = 0.1 #every chunk is 0.1 seconds\n",
        "    chunks = [None]*int(search_secs/c_dur)\n",
        "\n",
        "    # read the music in search range\n",
        "    iter = audio.iter_chunks(chunk_duration=c_dur)\n",
        "    for i in range(len(chunks)):\n",
        "      chunk = iter.__next__()\n",
        "      chunks[i] = chunk[:,0]\n",
        "\n",
        "    peaks = [(chunk.argmax(),chunk[chunk.argmax()]) for chunk in chunks]\n",
        "    peak_vals = [p[1] for p in peaks]\n",
        "    peak_ts = [(sec + p[0]*1/audio.fps)*c_dur for sec, p in zip(range(len(peaks)), peaks) ]\n",
        "    d_peaks = [0]+[t1-t0 for t0, t1 in zip(peak_vals[:-1], peak_vals[1:])]\n",
        "\n",
        "    is_master = False\n",
        "    fname = audio.filename\n",
        "    if fname.lower().startswith('m') and not is_finetune:\n",
        "      is_master = True\n",
        "      \n",
        "    if is_master:\n",
        "      tops = get_tops(peak_ts, peak_vals, d_peaks, 8)\n",
        "      clap_times = sorted([t for t, v in tops[:8]])[-4:]\n",
        "    else:\n",
        "      #clap_times = sorted([t for t, v in tops[:4]])\n",
        "      # clap_times = get_regular_patterns(sorted([t for t, v in tops[:8]]))\n",
        "      if is_finetune:\n",
        "        tops = get_tops(peak_ts, peak_vals, d_peaks, 8)\n",
        "        clap_times = get_regular_patterns(sorted([t for t, v in tops[:4]]))\n",
        "      else:\n",
        "        tops = get_tops(peak_ts, peak_vals, d_peaks, 10)\n",
        "        clap_times = get_regular_patterns(sorted([t for t, v in tops]))\n",
        "        cheat_list = {#\"A_Lina_1.MOV\":[4,5,6,7],\n",
        "                      #\"T_Preston.mp4\":[1,2,3,4] #,\n",
        "                      #\"T_Enoch_1.mp4\":[2,3,4,5]\n",
        "                      }\n",
        "        if fname in cheat_list:\n",
        "          sorted_t = sorted([t for t, v in tops])\n",
        "          clap_times = [sorted_t[i] for i in cheat_list[fname]]\n",
        "\n",
        "    #print (\"detected claps at \", np.array(clap_times))\n",
        "\n",
        "    diffs = [t1-t0 for t0, t1 in zip(clap_times[0:3], clap_times[1:4])]\n",
        "    #print(\"intervals: \", diffs)\n",
        "    est_intv = mean(diffs)\n",
        "    est=[0,0,0,0]\n",
        "    est[0] = clap_times[0]+est_intv*3.5\n",
        "    est[1] = clap_times[1]+est_intv*2.5\n",
        "    est[2] = clap_times[2]+est_intv*1.5\n",
        "    est[3] = clap_times[3]+est_intv*0.5\n",
        "\n",
        "    start_est = mean(est)\n",
        "    if INCLUDE_CLAPS or is_finetune==False:\n",
        "      start_est = start_est - est_intv*4\n",
        "    #print(\"start est:\", start_est)\n",
        "    \n",
        "    to_plot = lambda: plot_claps(fname, tops, peak_ts, peak_vals, d_peaks, clap_times)    \n",
        "    return start_est, est_intv, to_plot\n",
        "\n",
        "\n",
        "def plot_claps(fname, tops, peak_ts, peak_vals, d_peaks, clap_times):\n",
        "    print(\"\\n\"+fname+\"\\n\")\n",
        "    tops = np.array(tops)\n",
        "    p1 = plt.subplot(211)\n",
        "    plt.plot(peak_ts, peak_vals,  '-' ,color = \"red\")\n",
        "    plt.plot(tops[:,0], tops[:,1], \"x\")\n",
        "    p2 = plt.subplot(212)\n",
        "    plt.plot(peak_ts, d_peaks,'-', color = 'blue')\n",
        "    plt.plot(clap_times, [0]*len(clap_times), \"x\")\n",
        "    plt.show()\n",
        "\n",
        "def find_irregulars(ts):\n",
        "    start_times = ts[0]\n",
        "    est_beats = ts[1]\n",
        "    to_plot_funcs = ts[2]\n",
        "\n",
        "    beats_avg = mean(est_beats)\n",
        "    beats_var = var(est_beats)\n",
        "    for b, plot in zip(est_beats, to_plot_funcs):\n",
        "        if (b-beats_avg)**2 > 6*beats_var: #get outliers\n",
        "            print(\"irregular beats - expected:\", (beats_avg, std(est_beats)), \"actual:\", (b, (b-beats_avg)))\n",
        "            plot()\n",
        "        # plot()\n",
        "\n",
        "def estimate_start_x2(input_audios):\n",
        "    if len(input_audios) == 0:\n",
        "        return []\n",
        "    print([basename(a.filename) for a in input_audios])\n",
        "    t0s = [estimate_start(audio) for audio in input_audios]\n",
        "    t0s = list(zip(*t0s))#transpose t0s. t0s[0] is array of n elements of start_time\n",
        "    print(\"first round\")\n",
        "    find_irregulars(t0s)\n",
        "    t1s = [estimate_start(audio.subclip(t_start=max(st,0)), search_secs=5, is_finetune=True) \n",
        "    for audio, st in zip(input_audios, t0s[0])]\n",
        "    t1s = list(zip(*t1s))\n",
        "    print(\"second round\")\n",
        "    find_irregulars(t1s)\n",
        "    return [max(max(0,t0)+t1,0) for t0, t1 in zip(t0s[0],t1s[0])]\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6eA_Y5nZRfc",
        "colab_type": "text"
      },
      "source": [
        "## Sync "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqWup4ElL6BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_files(dir, glob_pattern):\n",
        "    return [filename for pattern in glob_pattern \n",
        "             for filename in glob.glob(dir+pattern)\n",
        "             if not basename(filename).startswith('_')]\n",
        "\n",
        "input_vids = [VideoFileClip(filename) for filename in get_files(RAW_PATH, VID_FILE_GLOBS)]\n",
        "vid_start_times = estimate_start_x2([v.audio for v in input_vids])\n",
        "input_vids = [v.subclip(t_start=st) for v,st in zip(input_vids, vid_start_times)]\n",
        "\n",
        "input_auds = [AudioFileClip(filename) for filename in get_files(RAW_PATH, AUD_FILE_GLOBS)]\n",
        "aud_start_times = estimate_start_x2(input_auds)\n",
        "input_auds = [a.subclip(t_start=st) for a,st in zip(input_auds, aud_start_times)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoCMVb23eahf",
        "colab_type": "text"
      },
      "source": [
        "### Write synced files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z0VDg5k7c2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vFx = lambda v:(v.resize(height=H/VID_DOWNSCALE_RATIO)\n",
        "    .fx(afx.audio_normalize)\n",
        "  )\n",
        "\n",
        "aFx = lambda a:(a.fx(afx.audio_normalize)\n",
        ")\n",
        "\n",
        "for v in input_vids:\n",
        "    if basename(v.filename) in to_process:\n",
        "        vo = vFx(v)\n",
        "        vo.write_videofile(INPUT_PATH+basename(v.filename), fps=30, codec='libx264', ffmpeg_params=['-crf','18'])\n",
        "\n",
        "for a in input_auds:\n",
        "    if basename(a.filename) in to_process:\n",
        "        ao = aFx(a)\n",
        "        ao.write_audiofile(INPUT_PATH+basename(a.filename), fps=44100, codec='mp3')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgRfa7CENwzO",
        "colab_type": "text"
      },
      "source": [
        "### Just syncing audio for now ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw9CMTVtNwKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from collections import defaultdict\n",
        "\n",
        "VOL_S = 20 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_A = 40 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_T = 60 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_B = 80 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_M = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "\n",
        "VOL = defaultdict(lambda:100, [\n",
        "    ('S', VOL_S), ('A', VOL_A), ('T', VOL_T), ('B', VOL_B)])\n",
        "\n",
        "out_auds = [AudioFileClip(filename) for filename in glob.glob(INPUT_PATH+\"*\")]\n",
        "\n",
        "def get_part(audio):\n",
        "    return basename(audio.filename)[0].upper()\n",
        "\n",
        "def get_part_vol(part):\n",
        "    return VOL[part]/100/log(len(out_auds))\n",
        "\n",
        "aud_groups = defaultdict(list)\n",
        "for a in out_auds:\n",
        "    aud_groups[get_part(a)].append(a)\n",
        "\n",
        "aud_parts = [(part, \n",
        "              CompositeAudioClip(auds)\n",
        "              .volumex(get_part_vol(part))) \n",
        "    for part, auds in aud_groups.items()]\n",
        "\n",
        "for part, aud in aud_parts:\n",
        "    aud.write_audiofile(OUTPUT_PATH+f\"output_{part}.mp3\", fps=44100, codec='mp3')\n",
        "\n",
        "cc = CompositeAudioClip([a for p, a in aud_parts])\n",
        "cc.write_audiofile(OUTPUT_PATH+\"output.mp3\", fps=44100, codec='mp3')\n",
        "# ipython_display(cc, fps=44100, maxduration=360)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_QhSaqVw89v",
        "colab_type": "text"
      },
      "source": [
        "### Create solo-group stereo track for comparison and study\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qms9U3hw7EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if OUTPUT_COMPARE:\n",
        "    cc_wavarray = cc.to_soundarray(fps=44100)[:,0]\n",
        "    for aud in out_auds:\n",
        "        fname = basename(aud.filename)\n",
        "        aud = aud.to_soundarray()[:,0]\n",
        "        mlen = min(len(aud), len(cc_wavarray))\n",
        "        mix = AudioArrayClip(np.transpose([aud[:mlen], cc_wavarray[:mlen]]), fps=44100)\n",
        "        mix.write_audiofile(OUTPUT_PATH+\"compare/\"+fname+\"_compare.mp3\", codec='mp3')\n",
        "\n",
        "if OUTPUT_SOLO:\n",
        "    for aud in out_auds:\n",
        "      aud.write_audiofile(OUTPUT_PATH+\"solo/\"+basename(aud.filename)+\".mp3\", codec='mp3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_PVpOTZ8fpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SATB_order(v):\n",
        "  key = ''\n",
        "  if 'filename' in v.__dict__:\n",
        "    filepath = v.filename\n",
        "    filename = basename(filepath)\n",
        "    key = filename[0].lower()\n",
        "  m={'s':0,'a':1,'t':2,'b':3}\n",
        "  if key in m.keys():\n",
        "    return m[key]\n",
        "  return randint(0,3)\n",
        "\n",
        "\n",
        "def get_vid_array_dim(n):\n",
        "  i=0 \n",
        "  while True:\n",
        "    i+=1\n",
        "    if i*i >= n:\n",
        "      break\n",
        "\n",
        "  if i*i == n:\n",
        "    return (i, i)\n",
        "  if (i-1)*i >= n:\n",
        "    return (i-1,i)\n",
        "  return (i,i)\n",
        "\n",
        "if OUTPUT_TILED_VID:\n",
        "    sub_height = H//10\n",
        "    if RENDER_SUBTITLE:\n",
        "        H -= sub_height\n",
        "\n",
        "    out_vids = [VideoFileClip(filename).set_audio(None) for filename in get_files(INPUT_PATH, VID_FILE_GLOBS)]\n",
        "    ROWS,COLS = get_vid_array_dim(len(out_vids))\n",
        "    clip_duration = max([i.duration for i in out_vids])\n",
        "    empty_clip = ColorClip((W//COLS,H//ROWS), (0,0,0), duration=clip_duration)\n",
        "    out_vids = out_vids+[empty_clip]*(ROWS*COLS-len(out_vids))\n",
        "    shuffle(out_vids)\n",
        "    out_vids.sort(key=SATB_order)\n",
        "\n",
        "    tiles = np.reshape(out_vids, (COLS, ROWS)) #dimension is inversed because need to transpose in next line\n",
        "    tiles = np.transpose(tiles)\n",
        "    if RENDER_SUBTITLE:\n",
        "        subspace_clip = ColorClip((W//COLS,sub_height), (0,0,0), duration=clip_duration)\n",
        "        tiles = np.vstack([tiles,[subspace_clip]*COLS])\n",
        "\n",
        "    cc = clips_array(tiles, cols_widths=[W//COLS]*COLS)\n",
        "    if RENDER_SUBTITLE:\n",
        "        cc = clips_array(tiles, cols_widths=[W//COLS]*COLS)\n",
        "    cc = cc.set_audio(AudioFileClip(OUTPUT_PATH+\"output.mp3\"))\n",
        "    # ipython_display(cc, t=10)\n",
        "    # cc=cc.subclip(40,60)\n",
        "    output_i=0\n",
        "    while os.path.exists(OUTPUT_PATH+f\"output{output_i}.mp4\"):\n",
        "        output_i += 1\n",
        "\n",
        "    cc.write_videofile(OUTPUT_PATH+f\"output{output_i}.mp4\", fps=30, codec='libx264', ffmpeg_params=['-crf','18'], threads=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPyIs7I5Hx7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -i \"$RAW_PATH\"\"$SUBTITLE_FILENAME\" subtitle.ass \n",
        "!ffmpeg -i \"$OUTPUT_PATH\"output\"$output_i\".mp4 -vf ass=subtitle.ass \"$OUTPUT_PATH\"output\"$output_i\"_sub_rendered.mp4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9bTVjXaXmNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}