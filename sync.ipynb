{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sync.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVHrQRJX7iZRnbn5Of2c5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k7sung/clap2choir/blob/master/sync.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zmn9XGN8q7U",
        "colab_type": "text"
      },
      "source": [
        "# For syncing & rendering videos & audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpIa_5FVtqri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3e8fcbb5-b641-4842-bcd6-7687eb717d37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiiPrWqxhWj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "GROUP = \"Test\" #@param [\"Praise Team\", \"VHR\", \"Combined Choir\", \"Chamber Instrumental\", \"Test\"] {type:\"string\", allow-input:true}\n",
        "SONG = \"Singing I Go\" #@param [\"Make My Life An Alleluia\", \"The Lord Is My Strength\", \"Singing I Go\", \"My Redeemer\", \"Sunshine In My Soul\", \"Day by Day\", \"I Will Exchange My Cross to Crown\", \"Hymn 157: Where Jesus Is, 'Tis Heaven\", \"Hymn 267: O For a Heart to Praise My God\", \"Hymn 420: Savior, Thy Dying Love\", \"Hymn 477: Then Jesus Came\", \"Hymn 479: O How He Loves You and Me\", \"Hymn 480: Wonderful, Wonderful Jesus\", \"Hymn 489: In My Heart There Rings a Melody\", \"Hymn 520: 'Twas Jesus' Blood\", \"Hymn 91: Thy Love, Jesus\"] {allow-input: true}\n",
        "DAY = 1 #@param {type:\"integer\"}\n",
        "RUN_SCRIPT_TO = \"check uploads\" #@param [\"check uploads\", \"the end\"]\n",
        "\n",
        "SHARED_FOLDER_PATH = 'Shared drives/MMP 2020 Participants' #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_MODE = \"mp3 only\" #@param [\"grid\", \"trimmed videos and audios\", \"mp3 only\"]\n",
        "\n",
        "VIDEO_RES = \"1280x720\" #@param [\"1920x1080\",\"1280x720\", \"854x480\", \"540x360\"] \n",
        "\n",
        "SONG_NAME = f\"{GROUP}/Day {DAY}/{SONG}\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sqAn7Rqlq1E",
        "colab_type": "text"
      },
      "source": [
        "### Optional Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyMFlhnOV83q",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "## OPTIONAL PARAMS ##\n",
        "#TIME_ZONE = 'US/Central' #@param [\"US/Central\", \"Europe/London\", \"Asia/Taipei\"] {allow-input:true}\n",
        "OUTPUT_SOLO = False #@param {type:\"boolean\"}\n",
        "OUTPUT_COMPARE = True #@param {type:\"boolean\"}\n",
        "OUTPUT_PARTS = False #@param {type:\"boolean\"}\n",
        "\n",
        "VID_DOWNSCALE_RATIO =  4#@param {type:\"integer\"}\n",
        "\n",
        "SUBTITLE_FILENAME = \"\" #@param {type:\"string\"}\n",
        "RENDER_SUBTITLE = SUBTITLE_FILENAME != \"\"\n",
        "\n",
        "KEEP_CLAPS = True #@param {type:\"boolean\"}\n",
        "DEBUG_PLOT = False #@param {type:\"boolean\"}\n",
        "\n",
        "NORMALIZE_VOLUME = True #@param {type:\"boolean\"}\n",
        "MORE_ALIGNMENT = False #@param {type:\"boolean\"}\n",
        "\n",
        "if OUTPUT_MODE == \"trimmed videos and audios\":\n",
        "  OUTPUT_SOLO = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "id42x_ikLNg1"
      },
      "source": [
        "## Mixer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "2UpTv8J-LNg1",
        "colab": {}
      },
      "source": [
        "VOL_S = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_A = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_T = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_B = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_M = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "VOL_OTHERS = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Violin1 = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Violin2 = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Viola = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Cello = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Bass = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Flute = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Clarinet = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Trumpet = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Trombone = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Cymbal = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "# V_Timpani = 100 #@param {type:\"slider\", min:0, max:100}\n",
        "from collections import defaultdict\n",
        "VOL = defaultdict(lambda:VOL_OTHERS, [\n",
        "    ('S', VOL_S), ('A', VOL_A), ('T', VOL_T), ('B', VOL_B)\n",
        "    # ,('VIOLIN1', V_Violin1),('VIOLIN2', V_Violin2), ('VIOLA', V_Viola), ('CELLO', V_Cello),('BASS', V_Bass),('FLUTE',V_Flute),('CLARINET', V_Clarinet), ('TRUMPET', V_Trumpet),(\"TROMBONE\", V_Trombone),(\"CYMBALS\",V_Cymbal),(\"TIMPANI\",V_Timpani)\n",
        "    ])\n",
        "\n",
        "REVERB = 0 #@param {type: \"slider\", min:0, max:10}\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvPqVKV686pU",
        "colab_type": "text"
      },
      "source": [
        "## Just Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kS0o5ajmzeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "1a721be6-2534-4a6b-d041-6f094340acb5"
      },
      "source": [
        "VID_FILE_GLOBS = [\"*.mov\", \"*.MOV\", \"*.mp4\", \"*.MP4\", \"*.m4v\"]\n",
        "AUD_FILE_GLOBS = [\"*.m4a\", \"*.mp3\", \"*.aac\", \"*.wav\", \"*.WAV\"]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import mean, median, std, var, diff, correlate as corr, zeros, transpose\n",
        "from moviepy.editor import *\n",
        "from moviepy.audio.AudioClip import AudioArrayClip\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from os.path import basename\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations as comb\n",
        "from random import shuffle, randint\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "if SHARED_FOLDER_PATH:\n",
        "    SHARED_DIR = \"/content/drive/\" + SHARED_FOLDER_PATH\n",
        "    RAW_PATH = SHARED_DIR + f\"/Inputs/{SONG_NAME}/\"\n",
        "    # OUTPUT_PATH = SHARED_DIR + f\"/outputs/{SONG_NAME}/{TODAY_DATE}/\"\n",
        "    OUTPUT_PATH = SHARED_DIR + f\"/Outputs/{SONG_NAME}/\"\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3661824/45929032 bytes (8.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7495680/45929032 bytes (16.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11485184/45929032 bytes (25.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15163392/45929032 bytes (33.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18579456/45929032 bytes (40.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b21938176/45929032 bytes (47.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25804800/45929032 bytes (56.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b29753344/45929032 bytes (64.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33628160/45929032 bytes (73.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37715968/45929032 bytes (82.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41598976/45929032 bytes (90.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45162496/45929032 bytes (98.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gM-LbC3JkIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "%mkdir -p \"$OUTPUT_PATH\"\n",
        "if OUTPUT_COMPARE:\n",
        "  %mkdir -p \"$OUTPUT_PATH\"compare\n",
        "if OUTPUT_SOLO:\n",
        "  %mkdir -p \"$OUTPUT_PATH\"solo\n",
        "if OUTPUT_MODE == \"trimmed videos and audios\":\n",
        "  %mkdir -p \"$OUTPUT_PATH\"vclips"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUaN-UmV90Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def is_conductingvideo(filename):\n",
        "    lbname = basename(filename).lower()\n",
        "    return ('master' in lbname) or ('conducting' in lbname) or ('conductor' in lbname) or (lbname.startswith('m_'))\n",
        "\n",
        "\n",
        "def get_loud_regular_patterns(tops, expected_n=4):\n",
        "    ts = [t for t, v in tops]\n",
        "    ls = [v for t, v in tops]\n",
        "    candi_vars = [(var(diff([ts[i] for i in c])), c) for c in comb(range(len(ts)), expected_n)]\n",
        "    candi_louds = [(sum([ls[i] for i in c]), c) for c in comb(range(len(ls)), expected_n)]\n",
        "    max_var = max([c[0] for c in candi_vars])\n",
        "    candi_vars = [(c[0] / max_var, c[1]) for c in candi_vars]\n",
        "    max_loud = max([c[0] for c in candi_louds])\n",
        "    candi_louds = [(-c[0] / max_loud, c[1]) for c in candi_louds]\n",
        "    scores = [(1.0 * v[0] + 0.3 * l[0], v[1]) for v, l in zip(candi_vars, candi_louds)]\n",
        "    most_regular = min(scores)\n",
        "    #    print(\"most regular\", most_regular)\n",
        "    return [ts[t] for t in most_regular[1]]\n",
        "\n",
        "\n",
        "def get_tops(peak_ts, peak_vals, d_peak_vals, top_n):\n",
        "    tops = sorted([(t, 0.0 * v + 1.0 * dv) for t, v, dv in zip(peak_ts, peak_vals, d_peak_vals)], key=lambda k: k[1],\n",
        "                  reverse=True)[:top_n]\n",
        "    # print(\"tops: \", tops)\n",
        "    return sorted(tops)\n",
        "\n",
        "\n",
        "def estimate_start(audio, search_secs=20, is_finetune=False):\n",
        "    c_dur = 0.1  # every chunk is 0.1 seconds\n",
        "    chunks = [None] * int(search_secs / c_dur)\n",
        "\n",
        "    # read the music in search range\n",
        "    iter = audio.iter_chunks(chunk_duration=c_dur)\n",
        "    for i in range(len(chunks)):\n",
        "        chunk = iter.__next__()\n",
        "        chunks[i] = chunk[:, 0]\n",
        "\n",
        "    peaks = [(chunk.argmax(), chunk[chunk.argmax()]) for chunk in chunks]\n",
        "    peak_vals = [p[1] for p in peaks]\n",
        "    peak_ts = [(sec + p[0] * 1 / audio.fps) * c_dur for sec, p in zip(range(len(peaks)), peaks)]\n",
        "    d_peaks = [0] + [t1 - t0 for t0, t1 in zip(peak_vals[:-1], peak_vals[1:])]\n",
        "\n",
        "    is_master = False\n",
        "    fname = basename(audio.filename)\n",
        "    if is_conductingvideo(fname) and not is_finetune:\n",
        "        print(\"this is is a conductor video\")\n",
        "        is_master = True\n",
        "\n",
        "    if is_master:\n",
        "        tops = get_tops(peak_ts, peak_vals, d_peaks, 16)\n",
        "        clap_times = get_loud_regular_patterns(tops, 8)[-4:]\n",
        "    else:\n",
        "        if is_finetune:\n",
        "            tops = get_tops(peak_ts, peak_vals, d_peaks, 8)\n",
        "            clap_times = get_loud_regular_patterns(tops)\n",
        "        else:\n",
        "            tops = get_tops(peak_ts, peak_vals, d_peaks, 12)\n",
        "            clap_times = get_loud_regular_patterns(tops)\n",
        "            cheat_list = {  # \"A_Lina_1.MOV\":[4,5,6,7],\n",
        "                # \"T_Preston.mp4\":[1,2,3,4] #,\n",
        "                # \"T_Enoch_1.mp4\":[2,3,4,5]\n",
        "            }\n",
        "            if fname in cheat_list:\n",
        "                sorted_t = sorted([t for t, v in tops])\n",
        "                clap_times = [sorted_t[i] for i in cheat_list[fname]]\n",
        "    est_intv = mean(diff(clap_times))\n",
        "    start_est = mean(clap_times) + est_intv * 2\n",
        "    if is_finetune == False:\n",
        "        start_est = start_est - est_intv * 4.4\n",
        "    # print(\"start est:\", start_est)\n",
        "\n",
        "    to_plot = lambda: plot_claps(fname, tops, peak_ts, peak_vals, d_peaks, clap_times)\n",
        "    return start_est, est_intv, to_plot\n",
        "\n",
        "\n",
        "def plot_claps(fname, tops, peak_ts, peak_vals, d_peaks, clap_times):\n",
        "    print(\"\\n\" + fname + \"\\n\")\n",
        "    tops = np.array(tops)\n",
        "    p1 = plt.subplot(211)\n",
        "    plt.plot(peak_ts, peak_vals, '-', color=\"red\")\n",
        "    plt.plot(tops[:, 0], tops[:, 1], \"x\")\n",
        "    p2 = plt.subplot(212)\n",
        "    plt.plot(peak_ts, d_peaks, '-', color='blue')\n",
        "    plt.plot(clap_times, [0] * len(clap_times), \"x\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def find_irregulars(ts):\n",
        "    start_times = ts[0]\n",
        "    est_beats = ts[1]\n",
        "    to_plot_funcs = ts[2]\n",
        "\n",
        "    beats_avg = mean(est_beats)\n",
        "    beats_var = var(est_beats)\n",
        "    irrs = []\n",
        "    for b, plot in zip(est_beats, to_plot_funcs):\n",
        "        if abs(b - beats_avg) > 0.15:\n",
        "            print(\"noticeable irregular beats - expected:\", (round(beats_avg, 3), round(std(est_beats), 3)),\n",
        "                  \"actual:\", (round(b, 3), round(abs(b - beats_avg), 3)))\n",
        "            if not DEBUG_PLOT:\n",
        "                plot()\n",
        "            irrs.append(True)\n",
        "        elif (b - beats_avg) ** 2 > 5 * beats_var:  # print outliers\n",
        "            print(\"maybe irregular beats - expected:\", (round(beats_avg, 3), round(std(est_beats), 3)),\n",
        "                  \"actual:\", (round(b, 3), round(abs(b - beats_avg), 3)))\n",
        "            if not DEBUG_PLOT:\n",
        "                plot()\n",
        "            irrs.append(False)\n",
        "        else:\n",
        "            irrs.append(False)\n",
        "        if DEBUG_PLOT:\n",
        "            plot()\n",
        "    return irrs\n",
        "\n",
        "def estimate_start_x2(input_audios):\n",
        "    if len(input_audios) == 0:\n",
        "        return []\n",
        "    print([basename(a.filename) for a in input_audios])\n",
        "    t0s = [estimate_start(audio) for audio in input_audios]\n",
        "    t0s = list(zip(*t0s))  # transpose t0s. t0s[0] is array of n elements of start_time\n",
        "    print(\"____________first round______________\")\n",
        "    find_irregulars(t0s)\n",
        "    t1s = [estimate_start(audio.subclip(t_start=max(st, 0)), search_secs=6, is_finetune=True)\n",
        "           for audio, st in zip(input_audios, t0s[0])]\n",
        "    t1s = list(zip(*t1s))\n",
        "    print(\"____________second round_____________\")\n",
        "    bads = find_irregulars(t1s)\n",
        "    return [max(max(0, t0) + t1, 0) for t0, t1 in zip(t0s[0], t1s[0])], bads\n",
        "\n",
        "\n",
        "def get_files(dir, glob_pattern):\n",
        "    return [filename for pattern in glob_pattern\n",
        "            for filename in glob.glob(dir + pattern)\n",
        "            if not basename(filename).startswith('_') and\n",
        "            not basename(filename).startswith('.') and\n",
        "            not 'delete' in basename(filename).lower()]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuO40rfK9DU9",
        "colab_type": "text"
      },
      "source": [
        "## Sync"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Um46BB9o-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_conductor_video():\n",
        "    # print(get_files(RAW_PATH, VID_FILE_GLOBS))\n",
        "    cond_vids = [VideoFileClip(filename)\n",
        "                 for filename in get_files(RAW_PATH, VID_FILE_GLOBS)\n",
        "                 if is_conductingvideo(filename)]\n",
        "\n",
        "    if cond_vids:\n",
        "        cond_vid = cond_vids[0]\n",
        "        cond_aud = cond_vid.audio\n",
        "        cond_start_times, bads = estimate_start_x2([cond_aud])\n",
        "        cond_start_time = cond_start_times[0]\n",
        "        print(\"vid start:\", cond_start_time)\n",
        "        return cond_vid, cond_start_time\n",
        "\n",
        "    cond_auds = [AudioFileClip(filename)\n",
        "                 for filename in get_files(RAW_PATH, AUD_FILE_GLOBS)\n",
        "                 if is_conductingvideo(filename)]\n",
        "    if cond_auds:\n",
        "        cond_aud = cond_auds[0]\n",
        "        cond_start_times, bads = estimate_start_x2([cond_aud])\n",
        "        cond_start_time = cond_start_times[0]\n",
        "        print(\"aud start:\", cond_start_time)\n",
        "        return cond_aud, cond_start_time\n",
        "    print(\"no conductor video found\")\n",
        "    return None, 5\n",
        "\n",
        "cond_vid, cond_start_time = get_conductor_video()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx5zdyaT98G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def align_files():\n",
        "    input_vids = []\n",
        "    for filename in get_files(RAW_PATH, VID_FILE_GLOBS):\n",
        "        if is_conductingvideo(filename):\n",
        "            continue\n",
        "        try:\n",
        "            v = VideoFileClip(filename)\n",
        "            print(basename(v.filename))\n",
        "            input_vids.append(v)\n",
        "        except (IndexError, OSError) as e:\n",
        "            print(\"*********** Cannot read **********\", basename(filename))\n",
        "            continue\n",
        "\n",
        "    if input_vids:\n",
        "        vid_start_times, vids_unaligned = estimate_start_x2([v.audio for v in input_vids])\n",
        "    else:\n",
        "        vid_start_times = []\n",
        "        vids_unaligned = []\n",
        "\n",
        "    if True in vids_unaligned:\n",
        "        print(\"irregular claps detected:\")\n",
        "        for i, is_bad in zip(input_vids, vids_unaligned):\n",
        "            if is_bad:\n",
        "                print(basename(i.filename))\n",
        "\n",
        "    input_auds = [AudioFileClip(filename) for filename in get_files(RAW_PATH, AUD_FILE_GLOBS)]\n",
        "    if len(input_auds) > 0:\n",
        "        aud_start_times, auds_unaligned = estimate_start_x2(input_auds)\n",
        "    else:\n",
        "        aud_start_times = []\n",
        "        auds_unaligned = []\n",
        "\n",
        "    if True in auds_unaligned:\n",
        "        print(\"irregular claps detected:\")\n",
        "        for i, is_bad in zip(input_auds, auds_unaligned):\n",
        "            if is_bad:\n",
        "                print(basename(i.filename))\n",
        "    return input_vids, vid_start_times, vids_unaligned, input_auds, aud_start_times, auds_unaligned\n",
        "\n",
        "\n",
        "input_vids, vid_start_times, vids_unaligned, input_auds, aud_start_times, auds_unaligned  = align_files()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfgwoTld9MyH",
        "colab_type": "text"
      },
      "source": [
        "### Write synced files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133Y5EuR-Emc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def transform_outputs(cond_vid, cond_start_time, input_vids, vid_start_times, vids_unaligned, input_auds,\n",
        "                      aud_start_times, auds_unaligned):\n",
        "    output_vids = []\n",
        "    output_auds = []\n",
        "    if KEEP_CLAPS:\n",
        "        output_vids = [(v.set_start(cond_start_time - st)) for v, st in zip(input_vids, vid_start_times)]\n",
        "        output_auds = [(a.set_start(cond_start_time - st)) for a, st in zip(input_auds, aud_start_times)]\n",
        "    else:\n",
        "        output_vids = [(v.subclip(t_start=st)\n",
        "                        .set_start(cond_start_time)) for v, st in zip(input_vids, vid_start_times)]\n",
        "        output_auds = [(a.subclip(t_start=st)\n",
        "                        .set_start(cond_start_time)) for a, st in zip(input_auds, aud_start_times)]\n",
        "\n",
        "    if cond_vid and isinstance(cond_vid, VideoClip):\n",
        "        if not 'invisible' in basename(cond_vid.filename):\n",
        "            output_vids = output_vids + [cond_vid]\n",
        "            output_auds = output_auds + [v.audio for v in output_vids]\n",
        "        else:\n",
        "            output_auds = output_auds + [v.audio for v in output_vids] + [cond_vid.audio]\n",
        "    elif cond_vid and isinstance(cond_vid, AudioClip):\n",
        "        output_auds = output_auds + [v.audio for v in output_vids] + [cond_vid]\n",
        "    else:\n",
        "        output_auds = output_auds + [v.audio for v in output_vids]\n",
        "\n",
        "    aud_start_times = aud_start_times + vid_start_times + [cond_start_time]\n",
        "    if NORMALIZE_VOLUME:\n",
        "        output_auds = normalize_audios(output_auds, aud_start_times)\n",
        "    output_vids = [v.set_audio(None) for v in output_vids]\n",
        "    return output_vids, output_auds\n",
        "\n",
        "\n",
        "def rms(audio):\n",
        "    a_arr = audio.to_soundarray(fps=44100)\n",
        "    return np.sqrt(np.mean(a_arr ** 2))\n",
        "\n",
        "\n",
        "# if RUN_SCRIPT_TO == \"the end\":\n",
        "def normalize_audios(output_auds, start_times=None):\n",
        "    if not start_times:\n",
        "        output_auds = [a.subclip(t_start=st) for a, st in zip(output_auds, start_times)]\n",
        "    peak_volumes = [a.max_volume() for a in output_auds]\n",
        "    rms_volumes = [rms(a) for a in output_auds]\n",
        "    rms_pnorm_volumes = [rms / p for rms, p in zip(rms_volumes, peak_volumes)]  # rms of audio after normalized\n",
        "    v_min = min(rms_pnorm_volumes)  # the rms of the quietest normalized audio\n",
        "\n",
        "    # reduce everyone's rms to within 120% of the quietest audio\n",
        "    target_vol_scales = [1 - (1 - v_min / v) * 0.8 for v in rms_pnorm_volumes]\n",
        "    output_auds = [a.volumex(tv / p) for a, p, tv in zip(output_auds, peak_volumes, target_vol_scales)]\n",
        "    return output_auds\n",
        "\n",
        "\n",
        "if RUN_SCRIPT_TO == \"the end\":\n",
        "    output_vids, output_auds = transform_outputs(cond_vid, cond_start_time, input_vids, vid_start_times, vids_unaligned, input_auds, aud_start_times, auds_unaligned)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QICrSe26-Sx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def is_muted(audio_filename):\n",
        "    if \"muted\" in basename(audio_filename).lower():\n",
        "        print(\"muted \", basename(audio_filename))\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def get_part(audio):\n",
        "    if is_conductingvideo(audio.filename):\n",
        "        return 'M'\n",
        "    if is_muted(audio.filename):\n",
        "        return 'Z'\n",
        "    bname = basename(audio.filename)\n",
        "    if '_' in bname:\n",
        "        return bname.split('_')[0].upper()\n",
        "    return bname[0].upper()\n",
        "\n",
        "\n",
        "def get_part_vol(part, output_auds):\n",
        "    if part == 'Z':\n",
        "        print(\"mute volume at \", VOL[part])\n",
        "    return VOL[part] / 100 / log(len(output_auds))\n",
        "\n",
        "\n",
        "from math import log\n",
        "\n",
        "\n",
        "def write_combined_audio_tracks(output_auds):\n",
        "    VOL[\"Z\"] = 0\n",
        "    aud_groups = defaultdict(list)\n",
        "    for a in output_auds:\n",
        "        aud_groups[get_part(a)].append(a)\n",
        "\n",
        "    aud_parts = [(part,\n",
        "                  CompositeAudioClip(auds)\n",
        "                  .volumex(get_part_vol(part, output_auds)))\n",
        "                 for part, auds in aud_groups.items()]\n",
        "\n",
        "    if OUTPUT_PARTS:\n",
        "        for part, aud in aud_parts:\n",
        "            aud.write_audiofile(OUTPUT_PATH + f\"output_{part}.mp3\", fps=44100, codec='mp3',\n",
        "                                ffmpeg_params=['-aq', '2'])\n",
        "\n",
        "    cc = CompositeAudioClip([a for p, a in aud_parts])\n",
        "    cc.write_audiofile(OUTPUT_PATH + \"output.mp3\", fps=44100, codec='mp3', ffmpeg_params=['-aq', '2'])\n",
        "\n",
        "\n",
        "if RUN_SCRIPT_TO == \"the end\":\n",
        "    write_combined_audio_tracks(output_auds)\n",
        "\n",
        "# ipython_display(cc, fps=44100, maxduration=360)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3eW2A-9j7X",
        "colab_type": "text"
      },
      "source": [
        "### Write extracted solo audio clips"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6JxGxB9-PWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def write_individual_clips(output_vids, output_auds):\n",
        "    vFx = lambda v: (v.resize(height=H / VID_DOWNSCALE_RATIO)\n",
        "                     )\n",
        "\n",
        "    if OUTPUT_MODE == \"trimmed videos and audios\":\n",
        "        for v in output_vids:\n",
        "            vo = vFx(v)\n",
        "            vo.write_videofile(OUTPUT_PATH + \"vclips/\" + basename(v.filename), fps=30, codec='libx264',\n",
        "                               ffmpeg_params=['-crf', '18'])\n",
        "\n",
        "    if OUTPUT_SOLO:\n",
        "        for a in output_auds:\n",
        "            b = CompositeAudioClip([a]).set_fps(44100)\n",
        "            b.write_audiofile(OUTPUT_PATH + \"solo/\" + basename(a.filename) + \".mp3\", fps=44100, codec='mp3',\n",
        "                              ffmpeg_params=['-aq', '2'])\n",
        "\n",
        "if RUN_SCRIPT_TO == \"the end\":\n",
        "  write_individual_clips(output_vids, output_auds)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DdBRYCa9s34",
        "colab_type": "text"
      },
      "source": [
        "### Write compare clips"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozRiIQFy-ZIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def write_compare_clips(output_auds):\n",
        "    if OUTPUT_COMPARE:\n",
        "        cc = AudioFileClip(OUTPUT_PATH + \"output.mp3\")\n",
        "        cc_wavarray = cc.to_soundarray(fps=44100)[:, 0]\n",
        "        for aud in output_auds:\n",
        "            fname = basename(aud.filename)\n",
        "            if OUTPUT_SOLO:\n",
        "                aud = AudioFileClip(OUTPUT_PATH + \"solo/\" + fname + \".mp3\").to_soundarray()[:, 0]\n",
        "            else:\n",
        "                aud = CompositeAudioClip([aud]).set_fps(44100).to_soundarray()[:, 0]\n",
        "            mlen = min(len(aud), len(cc_wavarray))\n",
        "            mix = AudioArrayClip(np.transpose([aud[:mlen], cc_wavarray[:mlen]-aud[:mlen]]), fps=44100)\n",
        "            mix.write_audiofile(OUTPUT_PATH + \"compare/\" + fname + \"_compare.mp3\", codec='mp3')\n",
        "\n",
        "if RUN_SCRIPT_TO == \"the end\":\n",
        "    write_compare_clips(output_auds)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltpm71yp94XF",
        "colab_type": "text"
      },
      "source": [
        "### Create video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hjNcdu7_EJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def SATB_order(v):\n",
        "    key = ''\n",
        "    if 'filename' in v.__dict__:\n",
        "        filepath = v.filename\n",
        "        filename = basename(filepath)\n",
        "        key = filename[0].lower()\n",
        "    m = {'s': 0, 'a': 1, 't': 2, 'b': 3}\n",
        "    if key in m.keys():\n",
        "        return m[key]\n",
        "    return randint(0, 3)\n",
        "\n",
        "\n",
        "def get_vid_array_dim(n):\n",
        "    i = 0\n",
        "    while True:\n",
        "        i += 1\n",
        "        if i * i >= n:\n",
        "            break\n",
        "\n",
        "    if i * i == n:\n",
        "        return (i, i)\n",
        "    if (i - 1) * i >= n:\n",
        "        return (i - 1, i)\n",
        "    return (i, i)\n",
        "\n",
        "\n",
        "def rotate_vid(vid):\n",
        "    if vid.rotation in [-90, 90, 270]:\n",
        "        vid = vid.resize(vid.size[::-1])\n",
        "        vid.rotation = 0\n",
        "    return vid\n",
        "\n",
        "\n",
        "def get_manual_row_col(filename):\n",
        "    fname = basename(filename)\n",
        "    r, c = 0, 0\n",
        "    if len(fname) >= 4:\n",
        "        if fname[0].upper() == 'R' and fname[2].upper() == 'C' and \\\n",
        "                fname[1] in '123456789' and fname[3] in '123456789':\n",
        "            r = int(fname[1])\n",
        "            c = int(fname[3])\n",
        "    return r, c\n",
        "\n",
        "\n",
        "def is_manual_layout(vids):\n",
        "    maxR = 0\n",
        "    maxC = 0\n",
        "    for v in vids:\n",
        "        r, c = get_manual_row_col(v.filename)\n",
        "        if r == 0 or c == 0:\n",
        "            maxR, maxC = 0, 0\n",
        "            break\n",
        "        maxR = max(maxR, r)\n",
        "        maxC = max(maxC, c)\n",
        "\n",
        "    if maxR == 0 or maxC == 0:\n",
        "        print(\"*** layout: automatic ***\")\n",
        "        r, c = get_vid_array_dim(len(vids))\n",
        "        return False, r, c\n",
        "    print(\"*** layout: manual ***\")\n",
        "    return True, maxR, maxC\n",
        "\n",
        "\n",
        "def generate_grid_video(output_vids, output_auds):\n",
        "    W, H = [int(t) for t in VIDEO_RES.split(\"x\")]\n",
        "    if OUTPUT_MODE == \"grid\":\n",
        "        sub_height = H // 10\n",
        "        if RENDER_SUBTITLE:\n",
        "            H -= sub_height\n",
        "\n",
        "        out_vids = output_vids\n",
        "        out_vids = [rotate_vid(v) for v in out_vids]\n",
        "        is_manual, ROWS, COLS = is_manual_layout(out_vids)\n",
        "        out_vids = [v.resize(height=H // ROWS) for v in out_vids]\n",
        "        out_vids = [v.crop(x_center=v.w // 2, width=min(W // COLS, v.w)) for v in out_vids]\n",
        "        clip_duration = max([i.duration for i in out_vids])\n",
        "        empty_clip = ColorClip((W // COLS, H // ROWS), (0, 0, 0), duration=clip_duration)\n",
        "        if is_manual:\n",
        "            tiles = np.full((ROWS, COLS), empty_clip)\n",
        "            for v in out_vids:\n",
        "                r, c = get_manual_row_col(v.filename)\n",
        "                tiles[r - 1, c - 1] = v\n",
        "        else:\n",
        "            out_vids = out_vids + [empty_clip] * (ROWS * COLS - len(out_vids))\n",
        "            shuffle(out_vids)\n",
        "            out_vids.sort(key=SATB_order)\n",
        "            tiles = np.reshape(out_vids, (COLS, ROWS))  # dimension is inversed because need to transpose in next line\n",
        "            tiles = np.transpose(tiles)\n",
        "\n",
        "        if RENDER_SUBTITLE:\n",
        "            subspace_clip = ColorClip((W // COLS, sub_height), (0, 0, 0), duration=clip_duration)\n",
        "            tiles = np.vstack([tiles, [subspace_clip] * COLS])\n",
        "\n",
        "        cc = clips_array(tiles, cols_widths=[W // COLS] * COLS)\n",
        "        if RENDER_SUBTITLE:\n",
        "            cc = clips_array(tiles, cols_widths=[W // COLS] * COLS)\n",
        "        cc = cc.set_audio(AudioFileClip(OUTPUT_PATH + \"output.mp3\"))\n",
        "\n",
        "        # cc.save_frame(\"preview.png\", t=10)\n",
        "        # cc=cc.subclip(40,60)\n",
        "        if H < 720:  # draft quality, saves time\n",
        "            f_params = []\n",
        "        else:\n",
        "            f_params = ['-crf', '18']\n",
        "\n",
        "        output_i = 0\n",
        "        while os.path.exists(OUTPUT_PATH + f\"output{output_i}.mp4\"):\n",
        "            output_i += 1\n",
        "        cc.write_videofile(OUTPUT_PATH + f\"output{output_i}.mp4\", fps=30, codec='libx264', ffmpeg_params=f_params,\n",
        "                           threads=4)\n",
        "\n",
        "\n",
        "if RUN_SCRIPT_TO == \"the end\":\n",
        "    generate_grid_video(output_vids, output_auds)\n"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}
